worker_processes  {{ .WorkerProcesses }};
daemon off;

error_log stderr {{ .LogLevel }};
pid {{ .WorkingDir }}/nginx.pid;

events {
    # Accept connections as fast as possible.
    multi_accept on;
    # Includes both proxy and client connections.
    # So e.g. 4096 = 2048 persistent client connections to backends per worker.
    worker_connections {{ .WorkerConnections }};
    # Use most optimal non-blocking selector on linux.
    # Should be selected by default on linux, we just make it explicit here.
    use epoll;
}

http {
    default_type text/html;

    # Track extended virtual host stats.
    vhost_traffic_status_zone;

    # Server names hash bucket sizes. Set based on nginx log messages.
    {{ if gt .ServerNamesHashBucketSize 0 }}server_names_hash_bucket_size {{ .ServerNamesHashBucketSize }};{{ end }}
    {{ if gt .ServerNamesHashMaxSize 0 }}server_names_hash_max_size {{ .ServerNamesHashMaxSize }};{{ end }}

    # Keep alive time for client connections. Don't limit by number of requests.
    keepalive_timeout {{ .KeepaliveSeconds }}s;
    keepalive_requests 2147483647;

    # Optimize for latency over throughput for persistent connections.
    tcp_nodelay on;

    # Disable nginx version leakage to external clients.
    server_tokens off;

    # Obtain client IP from frontend
{{ range .TrustedFrontends }}    set_real_ip_from {{ . }};
{{ end }}
    real_ip_header {{ if .ProxyProtocol }}proxy_protocol{{ else }}X-Forwarded-For{{ end }};
    real_ip_recursive on;

    # Log format tracking timings
    log_format upstream_info '$remote_addr - $remote_user [$time_iso8601] '
                             '"$request" $status{{.AccessLogHeaders}} $body_bytes_sent'
                             '"$http_referer" "$http_user_agent" '
                             '"$host" uip="$upstream_addr" ust="$upstream_status" '
                             'rt=$request_time uct="$upstream_connect_time" uht="$upstream_header_time" urt="$upstream_response_time"';

    # Access logs
    access_log {{ if .AccessLog }}{{ .AccessLogDir }}/access.log upstream_info buffer=32k flush=1m{{ else }}off{{ end }};

    # Disable all logging of 404s - to prevent spam when error log is enabled.
    log_not_found off;

    # Enable keepalive to backend.
    proxy_http_version 1.1;
    proxy_set_header Connection "";

    # Mitigate httpoxy vulnerability.
    proxy_set_header Proxy "";

    # Add headers for proxy information.
    map $http_x_forwarded_proto $frontend_scheme {
        default $http_x_forwarded_proto;
        '' $scheme;
    }
    map $http_x_forwarded_port $frontend_port {
        default $http_x_forwarded_port;
        '' $server_port;
    }
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Host $host:$frontend_port;
    proxy_set_header X-Forwarded-Proto $frontend_scheme;
    proxy_set_header X-Original-URI $request_uri;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header Host $host;

    # Timeout to backend services on initial connect.
    proxy_connect_timeout {{ .BackendConnectTimeoutSeconds }}s;

    # Disable buffering, as we'll be interacting with ELBs with http listeners, which we assume will
    # quickly consume and generate responses and requests.
    # This should be enabled if nginx will directly serve traffic externally to unknown clients.
    proxy_buffering off;

    # Don't mess with redirects.
    proxy_redirect off;

    # Start ingresses
    {{- $port := .IngressPort }}
    {{- $keepalive := .BackendKeepalives }}
    {{- $proxyprotocol := .ProxyProtocol }}
    
{{- range $upstream := .Upstreams }}
    upstream {{ $upstream.ID }} {
        server {{ $upstream.Server }};
        keepalive {{ $keepalive }};
    }
{{ end }}

{{- range $entry := .Servers }}
    # ingress: {{ $entry.Name }}
    server {
        listen {{ $port }}{{ if $proxyprotocol }} proxy_protocol{{ end }};
        server_name {{ $entry.ServerName }};

        # disable any limits to avoid HTTP 413 for large uploads
        client_max_body_size 0; 

        {{- range $location := $entry.Locations }}

        location {{ if $location.Path }}{{ $location.Path }}{{ end }} {
{{- if $location.StripPath }}
            # Strip location path when proxying.
            # Beware this can cause issues with url encoded characters.
            proxy_pass http://{{ $location.UpstreamID }}/;
{{- else }}
            # Keep original path when proxying.
            proxy_pass http://{{ $location.UpstreamID }};
{{- end }}

            # Set display name for vhost stats.
            vhost_traffic_status_filter_by_set_key {{ $location.Path }}::$proxy_host $server_name;

            # Close proxy connections after backend keepalive time.
            proxy_read_timeout {{ $location.BackendKeepaliveSeconds }}s;
            proxy_send_timeout {{ $location.BackendKeepaliveSeconds }}s;

            # Allow localhost for debugging
            allow 127.0.0.1;

            # Restrict clients
            {{ range $location.Allow }}allow {{ . }};
            {{ end }}
            deny all;
        }
        {{- end }}
    }
{{- end }}
    # End ingresses

    # Default backend
    server {
        listen {{ .IngressPort }} default_server;
        location / {
            return 404;
        }
    }

    # Status port. This should be firewalled to only allow internal access.
    server {
        listen {{ .HealthPort }} default_server reuseport;
        vhost_traffic_status off;

        location /health {
            access_log off;
            return 200;
        }

        location /basic_status {
            access_log off;
            stub_status;
        }

        location /status {
            access_log off;
            vhost_traffic_status_display;
            vhost_traffic_status_display_format html;
        }

        location / {
            return 404;
        }
    }
}
